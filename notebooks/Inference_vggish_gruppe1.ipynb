{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f52d7a-7b51-4928-8a09-12c300923cbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing\n",
    "#### As a prerequisite, first run the script below before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6583a737-008c-42b3-bcb7-b298eb93b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import vggish_input\n",
    "import tensorflow.compat.v1 as tf_compat\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "if not hasattr(tf_compat.flags, 'DEFINE_string'):\n",
    "    flags = tf_compat.app.flags\n",
    "else:\n",
    "    flags = tf_compat.flags\n",
    "\n",
    "if 'num_batches' not in flags.FLAGS:\n",
    "    flags.DEFINE_integer('num_batches', 30, 'Number of batches of examples to feed into the model.')\n",
    "\n",
    "if 'train_vggish' not in flags.FLAGS:\n",
    "    flags.DEFINE_boolean('train_vggish', True, 'If True, allow VGGish parameters to change during training.')\n",
    "\n",
    "if 'checkpoint' not in flags.FLAGS:\n",
    "    flags.DEFINE_string('checkpoint', 'vggish_model.ckpt', 'Path to the VGGish checkpoint file.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "_NUM_CLASSES = 2  # sarcastic and non sarcastic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aee3dc-1bd2-439c-90fd-9ce432e79234",
   "metadata": {},
   "source": [
    "# 1. Test with 4 audios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26fbf9-9603-46f8-80b4-f643852d0d66",
   "metadata": {},
   "source": [
    "### A) Data Loading and Labeling, Feature extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6dc27ab3-e0ea-45b7-8008-eeae952ca974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import vggish_input\n",
    "import tensorflow.compat.v1 as tf_compat\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "if not hasattr(tf_compat.flags, 'DEFINE_string'):\n",
    "    flags = tf_compat.app.flags\n",
    "else:\n",
    "    flags = tf_compat.flags\n",
    "\n",
    "if 'num_batches' not in flags.FLAGS:\n",
    "    flags.DEFINE_integer('num_batches', 30, 'Number of batches of examples to feed into the model.')\n",
    "\n",
    "if 'train_vggish' not in flags.FLAGS:\n",
    "    flags.DEFINE_boolean('train_vggish', True, 'If True, allow VGGish parameters to change during training.')\n",
    "\n",
    "if 'checkpoint' not in flags.FLAGS:\n",
    "    flags.DEFINE_string('checkpoint', 'vggish_model.ckpt', 'Path to the VGGish checkpoint file.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "_NUM_CLASSES = 2  # sarcastic and non sarcastic \n",
    "\n",
    "#  Path to JSON file and folder containing audio files\n",
    "json_path = '/Users/pierrekolingba-froidevaux/Desktop/Deep_Learning/MUStARD-master/data/sarcasm_data.json'\n",
    "audio_folder_path = './utterances_final_wav/'\n",
    "\n",
    "# Load JSON Datas\n",
    "with open(json_path, 'r') as f:\n",
    "    labels_data = json.load(f)\n",
    "\n",
    "# Specific list of uploaded Data\n",
    "audio_files = ['2_99.wav', '2_97.wav', '2_96.wav', '2_94.wav', '2_91.wav']\n",
    "\n",
    "def _get_examples_batch(audio_folder_path, labels_data, audio_files):\n",
    "    batch_features = []\n",
    "    batch_labels = []\n",
    "\n",
    "    for file_name in audio_files:\n",
    "        file_path = os.path.join(audio_folder_path, file_name)\n",
    "\n",
    "        # Load Data and convert it in examples format\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        examples = vggish_input.waveform_to_examples(audio, sr)\n",
    "\n",
    "        # Get audio file label from JSON data\n",
    "        # Assuming that the file name without '.wav' is used as the key in the JSON\n",
    "        is_sarcastic = labels_data[file_name.replace('.wav', '')][\"sarcasm\"]\n",
    "        label = [1, 0] if is_sarcastic else [0, 1]\n",
    "\n",
    "        # Add examples and label to batch\n",
    "        for example in examples:\n",
    "            batch_features.append(example)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "    return np.array(batch_features), np.array(batch_labels)\n",
    "\n",
    "# Use the modified function to load your 4 specific audio files\n",
    "features, labels = _get_examples_batch(audio_folder_path, labels_data, audio_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea47560-7656-4242-8044-c3b319a039b1",
   "metadata": {},
   "source": [
    "### B) Embedding through inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "983f31e5-790f-4407-9014-8d50188158ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:318: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "I0214 13:13:01.751516 8695358720 saver.py:1413] Restoring parameters from vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import vggish_slim, vggish_params, vggish_postprocess\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure tf.compat.v1 is used for TensorFlow and disable dynamic execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def extract_embeddings(features):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # Initialize VGGish and load the checkpoint\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "\n",
    "        # Locate input and output tensors\n",
    "        features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "        # Initialize the post-processor\n",
    "        pproc = vggish_postprocess.Postprocessor(FLAGS.pca_params)\n",
    "\n",
    "        # Run the model to obtain embeddings\n",
    "        [embedding_batch] = sess.run([embedding_tensor], feed_dict={features_tensor: features})\n",
    "\n",
    "        # Apply post-processing - PCA (whitens the data) - Loss function way higher with it though\n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        \n",
    "        return postprocessed_batch\n",
    "\n",
    "# Running the embedding extraction function with post-processing\n",
    "embedding_batch = extract_embeddings(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding_batch, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b05cb23-4ea4-41e2-954f-13aced7574af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 96, 64)\n",
      "(19, 2)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0af27b-2228-4065-8565-f3534aa19d19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### C) Training with embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ddd89c5-1404-47d5-aa41-2714178c828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss 0.000542271591257304\n",
      "Batch 1: Loss 1.8461765449728773e-08\n",
      "Batch 2: Loss 1.86176872529753e-11\n",
      "Batch 3: Loss 8.987028379510778e-14\n",
      "Batch 4: Loss 1.1381868644666916e-15\n",
      "Batch 5: Loss 2.834255952190879e-17\n",
      "Batch 6: Loss 1.1755497954812667e-18\n",
      "Batch 7: Loss 7.295782762801428e-20\n",
      "Batch 8: Loss 6.292498225113345e-21\n",
      "Batch 9: Loss 7.145279936261015e-22\n",
      "Batch 10: Loss 1.0254011000870219e-22\n",
      "Batch 11: Loss 1.7995859423639933e-23\n",
      "Batch 12: Loss 3.765552589286504e-24\n",
      "Batch 13: Loss 9.189628039384557e-25\n",
      "Batch 14: Loss 2.569959931714196e-25\n",
      "Batch 15: Loss 8.112444636281087e-26\n",
      "Batch 16: Loss 2.8527589241459094e-26\n",
      "Batch 17: Loss 1.1051104658178534e-26\n",
      "Batch 18: Loss 4.672428919413886e-27\n",
      "Batch 19: Loss 2.136021938300662e-27\n",
      "Batch 20: Loss 1.0484386097939984e-27\n",
      "Batch 21: Loss 5.486469336431319e-28\n",
      "Batch 22: Loss 3.043260368294678e-28\n",
      "Batch 23: Loss 1.7792874717504043e-28\n",
      "Batch 24: Loss 1.0916262406459211e-28\n",
      "Batch 25: Loss 6.994260750963264e-29\n",
      "Batch 26: Loss 4.6622578065251476e-29\n",
      "Batch 27: Loss 3.221208109953795e-29\n",
      "Batch 28: Loss 2.3004519989773e-29\n",
      "Batch 29: Loss 1.6924851170257978e-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import vggish_params\n",
    "\n",
    "# Ensure tf.compat.v1 is used for TensorFlow\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        embeddings_input = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]], name='embeddings_input')\n",
    "        labels_input = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='labels_input')\n",
    "\n",
    "        # Definition of the classification model\n",
    "        with tf.variable_scope('mymodel'):\n",
    "            fc = slim.fully_connected(embeddings_input, 100, activation_fn=tf.nn.relu)\n",
    "            logits = slim.fully_connected(fc, _NUM_CLASSES, activation_fn=None)\n",
    "\n",
    "        # Loss and optimizer\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels_input))\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=vggish_params.LEARNING_RATE, epsilon=vggish_params.ADAM_EPSILON).minimize(loss)\n",
    "\n",
    "        # Initialization of variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Training loop\n",
    "        for i in range(FLAGS.num_batches):\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={embeddings_input: X_train, labels_input: y_train})\n",
    "            print(f'Batch {i}: Loss {loss_value}')\n",
    "\n",
    "        # Calculation of logits on the test set\n",
    "        logits_test = sess.run(logits, feed_dict={embeddings_input: X_test})\n",
    "\n",
    "        # Conversion of logits to binary predictions\n",
    "        predictions = tf.round(tf.sigmoid(logits_test))\n",
    "        predicted_classes = sess.run(predictions)\n",
    "\n",
    "        # Evaluation\n",
    "        print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "# Execution of training and evaluation\n",
    "train_and_evaluate_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88abc28-ecba-4889-b1a5-d179e4368130",
   "metadata": {},
   "source": [
    "# 2. With original audio data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1afd7-dabf-40bf-bf0f-5d37181bfa33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### A) Data Loading, labeling, extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eb282c7e-1da1-44e0-908d-4432031e5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import vggish_input\n",
    "import glob\n",
    "\n",
    "# Path to the JSON file and the folder containing the audio files\n",
    "json_path = '/Users/pierrekolingba-froidevaux/Desktop/Deep_Learning/MUStARD-master/data/sarcasm_data.json'\n",
    "audio_folder_path = './utterances_final_wav/'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_path, 'r') as f:\n",
    "    labels_data = json.load(f)\n",
    "\n",
    "# Function to generate batches of examples and labels\n",
    "def get_all_examples(audio_folder_path, labels_data):\n",
    "    audio_files = glob.glob(os.path.join(audio_folder_path, '*.wav'))\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for file_path in audio_files:\n",
    "        file_name = os.path.basename(file_path).replace('.wav', '')\n",
    "\n",
    "        # Load the audio and convert it into an example\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        examples = vggish_input.waveform_to_examples(audio, sr)\n",
    "\n",
    "        # Get the audio file's label from the JSON data\n",
    "        is_sarcastic = labels_data[file_name][\"sarcasm\"]\n",
    "        label = [1, 0] if is_sarcastic else [0, 1]  # [sarcasm, non-sarcasm]\n",
    "\n",
    "        for example in examples:\n",
    "            all_features.append(example)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return np.array(all_features), np.array(all_labels)\n",
    "\n",
    "features, labels = get_all_examples(audio_folder_path, labels_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c5293-44b6-4e45-b95f-e5134cac0f63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### B) Embedding through inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8698304-9906-4dfa-90db-d71476dbe22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:318: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "I0214 14:21:43.427644 8695358720 saver.py:1413] Restoring parameters from vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import vggish_slim, vggish_params, vggish_postprocess\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure tf.compat.v1 is used for TensorFlow and disable dynamic execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def extract_embeddings(features):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # Initialize VGGish and load the checkpoint\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "\n",
    "        # Locate input and output tensors\n",
    "        features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "        # Initialize the post-processor\n",
    "        pproc = vggish_postprocess.Postprocessor(FLAGS.pca_params)\n",
    "\n",
    "        # Run the model to obtain embeddings\n",
    "        [embedding_batch] = sess.run([embedding_tensor], feed_dict={features_tensor: features})\n",
    "\n",
    "        # Apply post-processing - PCA (whitens the data) - Loss function way higher with it though\n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        \n",
    "        return postprocessed_batch\n",
    "\n",
    "# Running the embedding extraction function with post-processing\n",
    "embedding_batch = extract_embeddings(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding_batch, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "281d2ccf-2838-4a70-9224-338d274b0563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3475, 128)\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "[[ 41 124 227 ... 117 255   0]\n",
      " [ 57 234 255 ... 231 185 255]\n",
      " [114 127 229 ... 255 255  99]\n",
      " ...\n",
      " [ 61 147 250 ...   6 255 255]\n",
      " [ 83 135 226 ...   0 255   0]\n",
      " [ 93  84 220 ...  74 112 213]]\n",
      "[[ 79  78 201 ... 228  69 154]\n",
      " [  0 255 255 ...   0 255 255]\n",
      " [ 96 133 255 ...   0 255 255]\n",
      " ...\n",
      " [ 53 149 230 ...   0 255 197]\n",
      " [139  76 197 ... 231   0 255]\n",
      " [107  84 201 ... 193  75 113]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_batch.shape)\n",
    "print(labels)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a620a6-d81a-4ce8-878f-f87908e29f25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### C) Training with embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "001e248f-febf-4e20-b377-20c8ffabaec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss 17.407608032226562\n",
      "Batch 1: Loss 66.51174926757812\n",
      "Batch 2: Loss 62.00385665893555\n",
      "Batch 3: Loss 57.76488494873047\n",
      "Batch 4: Loss 29.130760192871094\n",
      "Batch 5: Loss 9.929426193237305\n",
      "Batch 6: Loss 30.343368530273438\n",
      "Batch 7: Loss 28.99596405029297\n",
      "Batch 8: Loss 26.74911117553711\n",
      "Batch 9: Loss 14.744040489196777\n",
      "Batch 10: Loss 8.207809448242188\n",
      "Batch 11: Loss 16.846784591674805\n",
      "Batch 12: Loss 20.67616844177246\n",
      "Batch 13: Loss 17.20814323425293\n",
      "Batch 14: Loss 9.673805236816406\n",
      "Batch 15: Loss 7.701658725738525\n",
      "Batch 16: Loss 9.110270500183105\n",
      "Batch 17: Loss 11.665075302124023\n",
      "Batch 18: Loss 12.829596519470215\n",
      "Batch 19: Loss 7.583329677581787\n",
      "Batch 20: Loss 5.015645980834961\n",
      "Batch 21: Loss 6.973839282989502\n",
      "Batch 22: Loss 7.815910339355469\n",
      "Batch 23: Loss 8.395711898803711\n",
      "Batch 24: Loss 5.433155536651611\n",
      "Batch 25: Loss 2.6407253742218018\n",
      "Batch 26: Loss 6.027275085449219\n",
      "Batch 27: Loss 6.338827610015869\n",
      "Batch 28: Loss 3.2198662757873535\n",
      "Batch 29: Loss 3.1518027782440186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       392\n",
      "           1       0.65      0.33      0.44       303\n",
      "\n",
      "   micro avg       0.59      0.70      0.64       695\n",
      "   macro avg       0.61      0.66      0.58       695\n",
      "weighted avg       0.61      0.70      0.60       695\n",
      " samples avg       0.60      0.70      0.64       695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import vggish_params\n",
    "\n",
    "# Ensure tf.compat.v1 is used for TensorFlow\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test, _NUM_CLASSES):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # Placeholders for embeddings and labels\n",
    "        embeddings_input = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]], name='embeddings_input')\n",
    "        labels_input = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='labels_input')\n",
    "\n",
    "        # Definition of the new top layer for VGGish\n",
    "        with tf.variable_scope('vggish_adapted'):\n",
    "            # Adding a layer of Global Average Pooling - Dimensions are different, Gao's paper not specific about it\n",
    "            #net = tf.reduce_mean(embeddings_input, axis=[1, 2], keepdims=True, name='global_avg_pool')\n",
    "            net = embeddings_input  # Correction here\n",
    "            \n",
    "            # First fully connected layer adapted\n",
    "            net = slim.fully_connected(net, 4096, activation_fn=tf.nn.relu, scope='fc_adapted1')\n",
    "            \n",
    "            # Second fully connected layer adapted\n",
    "            net = slim.fully_connected(net, 4096, activation_fn=tf.nn.relu, scope='fc_adapted2')\n",
    "            \n",
    "            # Logits layer for classification adapted to the new task\n",
    "            logits = slim.fully_connected(net, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
    "\n",
    "        # Loss and optimizer\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels_input))\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=vggish_params.LEARNING_RATE, epsilon=vggish_params.ADAM_EPSILON).minimize(loss)\n",
    "\n",
    "        # Initialization of variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Training loop\n",
    "        for i in range(FLAGS.num_batches):\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={embeddings_input: X_train, labels_input: y_train})\n",
    "            print(f'Batch {i}: Loss {loss_value}')\n",
    "\n",
    "        # Calculation of logits on the test set\n",
    "        logits_test = sess.run(logits, feed_dict={embeddings_input: X_test})\n",
    "\n",
    "        # Conversion of logits to binary predictions\n",
    "        predictions = tf.round(tf.sigmoid(logits_test))\n",
    "        predicted_classes = sess.run(predictions)\n",
    "\n",
    "        # Evaluation\n",
    "        print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "train_and_evaluate_model(X_train, y_train, X_test, y_test, _NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "03894dfd-41a4-4e90-874a-b6f8b5230cbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2769, 128)\n",
      "y_train shape: (2769, 2)\n",
      "X_test shape: (693, 128)\n",
      "y_test shape: (693, 2)\n",
      "Num batches: 30\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum batches:\u001b[39m\u001b[38;5;124m\"\u001b[39m, FLAGS\u001b[38;5;241m.\u001b[39mnum_batches)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, predicted_classes))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_classes' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"Num batches:\", FLAGS.num_batches)\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e25e95-5c1d-4b42-95c5-88b8f5eef827",
   "metadata": {},
   "source": [
    "# 3. With denoised audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258201a1-3d6b-46cb-83ab-07f6183104f5",
   "metadata": {},
   "source": [
    "### A) Data Loading, labeling, extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8cbf0fed-665c-4f74-87f1-444e97a90ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import vggish_input\n",
    "import glob\n",
    "\n",
    "# Path to the JSON file and the folder containing the audio files\n",
    "json_path = '/Users/pierrekolingba-froidevaux/Desktop/Deep_Learning/MUStARD-master/data/sarcasm_data.json'\n",
    "audio_folder_path = './raw_audio_pcm_f32le_16kHz_denoised/'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_path, 'r') as f:\n",
    "    labels_data = json.load(f)\n",
    "\n",
    "# Function to generate batches of examples and labels\n",
    "def get_all_examples(audio_folder_path, labels_data):\n",
    "    audio_files = glob.glob(os.path.join(audio_folder_path, '*.wav'))\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for file_path in audio_files:\n",
    "        file_name = os.path.basename(file_path).replace('.wav', '')\n",
    "\n",
    "        # Load the audio and convert it into an example\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        examples = vggish_input.waveform_to_examples(audio, sr)\n",
    "\n",
    "        # Get the audio file's label from the JSON data\n",
    "        is_sarcastic = labels_data[file_name][\"sarcasm\"]\n",
    "        label = [1, 0] if is_sarcastic else [0, 1]  # [sarcasm, non-sarcasm]\n",
    "\n",
    "        for example in examples:\n",
    "            all_features.append(example)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return np.array(all_features), np.array(all_labels)\n",
    "\n",
    "features, labels = get_all_examples(audio_folder_path, labels_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef730d48-84f3-45bf-b3c8-39b6d3fb48dc",
   "metadata": {},
   "source": [
    "### B) Embedding through inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "318c1b80-f0e9-4772-9f60-ffec6c942f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:318: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "I0214 14:33:42.046692 8695358720 saver.py:1413] Restoring parameters from vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import vggish_slim, vggish_params, vggish_postprocess\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure tf.compat.v1 is used for TensorFlow and disable dynamic execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def extract_embeddings(features):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # Initialize VGGish and load the checkpoint\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "\n",
    "        # Locate input and output tensors\n",
    "        features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "        # Initialize the post-processor\n",
    "        pproc = vggish_postprocess.Postprocessor(FLAGS.pca_params)\n",
    "\n",
    "        # Run the model to obtain embeddings\n",
    "        [embedding_batch] = sess.run([embedding_tensor], feed_dict={features_tensor: features})\n",
    "\n",
    "        # Apply post-processing - PCA (whitens the data) - Loss function way higher with it though\n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        \n",
    "        return postprocessed_batch\n",
    "\n",
    "# Running the embedding extraction function with post-processing\n",
    "embedding_batch = extract_embeddings(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding_batch, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94e12290-7787-4d3f-9dcb-004988101cc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3462, 128)\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "[[ 67  56 120 ... 159 124 255]\n",
      " [ 93 101  88 ...  82 127 205]\n",
      " [ 85  60 165 ...   0 101 255]\n",
      " ...\n",
      " [ 35  76 115 ...  56 255   0]\n",
      " [ 56 120  96 ... 255 255  63]\n",
      " [132  88 143 ... 139  86 255]]\n",
      "[[ 78  84 127 ... 247   0 140]\n",
      " [101  42 175 ...  11 255  69]\n",
      " [ 41  80 122 ... 208 129 153]\n",
      " ...\n",
      " [ 70  88 151 ...   0 127 240]\n",
      " [ 90  81  76 ...   0 189 255]\n",
      " [ 74 106 117 ...  69   0 255]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ...\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_batch.shape)\n",
    "print(labels)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82baed1-48ae-431e-aabf-f538bcb954a7",
   "metadata": {},
   "source": [
    "### C) Training with embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cff02a80-2ff0-440e-80df-875105376090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss 7.961370468139648\n",
      "Batch 1: Loss 66.02604675292969\n",
      "Batch 2: Loss 69.88257598876953\n",
      "Batch 3: Loss 48.334922790527344\n",
      "Batch 4: Loss 27.800418853759766\n",
      "Batch 5: Loss 5.777182102203369\n",
      "Batch 6: Loss 29.18089485168457\n",
      "Batch 7: Loss 41.489315032958984\n",
      "Batch 8: Loss 39.91816711425781\n",
      "Batch 9: Loss 31.94264030456543\n",
      "Batch 10: Loss 17.72698211669922\n",
      "Batch 11: Loss 2.9278132915496826\n",
      "Batch 12: Loss 13.160613059997559\n",
      "Batch 13: Loss 19.01643180847168\n",
      "Batch 14: Loss 21.5030574798584\n",
      "Batch 15: Loss 20.49531364440918\n",
      "Batch 16: Loss 16.61652183532715\n",
      "Batch 17: Loss 11.16903305053711\n",
      "Batch 18: Loss 3.711963415145874\n",
      "Batch 19: Loss 6.547635555267334\n",
      "Batch 20: Loss 12.289713859558105\n",
      "Batch 21: Loss 13.327323913574219\n",
      "Batch 22: Loss 10.96654987335205\n",
      "Batch 23: Loss 5.512005805969238\n",
      "Batch 24: Loss 2.597316265106201\n",
      "Batch 25: Loss 6.385324954986572\n",
      "Batch 26: Loss 8.423666954040527\n",
      "Batch 27: Loss 8.374922752380371\n",
      "Batch 28: Loss 6.657341957092285\n",
      "Batch 29: Loss 3.4592630863189697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       392\n",
      "           1       0.49      0.72      0.58       301\n",
      "\n",
      "   micro avg       0.53      0.63      0.58       693\n",
      "   macro avg       0.53      0.64      0.58       693\n",
      "weighted avg       0.54      0.63      0.58       693\n",
      " samples avg       0.45      0.63      0.51       693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrekolingba-froidevaux/anaconda3/envs/new_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import vggish_params\n",
    "\n",
    "# Ensure tf.compat.v1 is used for TensorFlow\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test, _NUM_CLASSES):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # Placeholders for embeddings and labels\n",
    "        embeddings_input = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]], name='embeddings_input')\n",
    "        labels_input = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='labels_input')\n",
    "\n",
    "        # Definition of the new top layer for VGGish\n",
    "        with tf.variable_scope('vggish_adapted'):\n",
    "            # Adding a layer of Global Average Pooling - Dimensions are different, Gao's paper not specific about it\n",
    "            #net = tf.reduce_mean(embeddings_input, axis=[1, 2], keepdims=True, name='global_avg_pool')\n",
    "            net = embeddings_input  # Correction here\n",
    "            \n",
    "            # First adapted fully connected layer\n",
    "            net = slim.fully_connected(net, 4096, activation_fn=tf.nn.relu, scope='fc_adapted1')\n",
    "            \n",
    "            # Second adapted fully connected layer\n",
    "            net = slim.fully_connected(net, 4096, activation_fn=tf.nn.relu, scope='fc_adapted2')\n",
    "            \n",
    "            # Logits layer for classification adapted to the new task\n",
    "            logits = slim.fully_connected(net, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
    "\n",
    "        # Loss and optimizer\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels_input))\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=vggish_params.LEARNING_RATE, epsilon=vggish_params.ADAM_EPSILON).minimize(loss)\n",
    "\n",
    "        # Initialization of variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Training loop\n",
    "        for i in range(FLAGS.num_batches):\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={embeddings_input: X_train, labels_input: y_train})\n",
    "            print(f'Batch {i}: Loss {loss_value}')\n",
    "\n",
    "        # Calculation of logits on the test set\n",
    "        logits_test = sess.run(logits, feed_dict={embeddings_input: X_test})\n",
    "\n",
    "        # Conversion of logits to binary predictions\n",
    "        predictions = tf.round(tf.sigmoid(logits_test))\n",
    "        predicted_classes = sess.run(predictions)\n",
    "\n",
    "        # Evaluation\n",
    "        print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "train_and_evaluate_model(X_train, y_train, X_test, y_test, _NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961fe02-af89-44fc-9fe3-83c66cb8eda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
